# metal_wyvern

Step 1 - Keep as is, but in Rust. Serve the same ONNX model on an axum server.

Step 2 - Convert ONNX model to Burn model, just run inference via that model with Burn

Step 3 - Try different training and architectures, all within Burn, updating and servering as needed
