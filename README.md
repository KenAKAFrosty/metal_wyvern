# metal_wyvern

-   [x] Step 1 - Keep as is, but in Rust. Serve the same ONNX model on an axum server.

-   [x] Step 2 - Convert ONNX model to Burn model, just run inference via that model with Burn

-   [ ] Step 3 - Try different training and architectures, all within Burn, updating and serving as needed
