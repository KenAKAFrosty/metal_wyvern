{"key":{"key":{"Conv2d":{"kernel_size":[3,3],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":8,"out_channels":32,"shape":[16,16],"batch_size":64,"has_bias":true,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":117811},"median":{"secs":0,"nanos":118528},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":114432},"max":{"secs":0,"nanos":121344}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":180736},"median":{"secs":0,"nanos":180736},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":179968},"max":{"secs":0,"nanos":181504}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[3,3],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":32,"out_channels":64,"shape":[16,16],"batch_size":64,"has_bias":true,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":349926},"median":{"secs":0,"nanos":348928},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":344576},"max":{"secs":0,"nanos":361728}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":2936678},"median":{"secs":0,"nanos":2811904},"variance":{"secs":0,"nanos":243},"min":{"secs":0,"nanos":2619136},"max":{"secs":0,"nanos":4371200}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[3,3],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":64,"out_channels":128,"shape":[16,16],"batch_size":64,"has_bias":true,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":1922662},"median":{"secs":0,"nanos":2366208},"variance":{"secs":0,"nanos":407},"min":{"secs":0,"nanos":929024},"max":{"secs":0,"nanos":2436096}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":10795776},"median":{"secs":0,"nanos":10799872},"variance":{"secs":0,"nanos":23},"min":{"secs":0,"nanos":10569216},"max":{"secs":0,"nanos":11071744}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[11,11],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":64,"out_channels":128,"shape":[16,16],"batch_size":64,"has_bias":false,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":4919987},"median":{"secs":0,"nanos":4994560},"variance":{"secs":0,"nanos":48},"min":{"secs":0,"nanos":4657152},"max":{"secs":0,"nanos":5167360}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":112045619},"median":{"secs":0,"nanos":111992576},"variance":{"secs":0,"nanos":625},"min":{"secs":0,"nanos":110616576},"max":{"secs":0,"nanos":113622272}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[11,11],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":64,"out_channels":64,"shape":[16,16],"batch_size":32,"has_bias":false,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":3061683},"median":{"secs":0,"nanos":3093248},"variance":{"secs":0,"nanos":17},"min":{"secs":0,"nanos":2876416},"max":{"secs":0,"nanos":3300352}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":12766438},"median":{"secs":0,"nanos":12932096},"variance":{"secs":0,"nanos":54},"min":{"secs":0,"nanos":12404992},"max":{"secs":0,"nanos":13055232}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[11,11],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":64,"out_channels":32,"shape":[16,16],"batch_size":8,"has_bias":false,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":2779033},"median":{"secs":0,"nanos":2732544},"variance":{"secs":0,"nanos":26},"min":{"secs":0,"nanos":2638080},"max":{"secs":0,"nanos":3193856}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":2908518},"median":{"secs":0,"nanos":2961408},"variance":{"secs":0,"nanos":30},"min":{"secs":0,"nanos":2652416},"max":{"secs":0,"nanos":3170048}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[3,3],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":8,"out_channels":32,"shape":[16,16],"batch_size":32,"has_bias":true,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":68377},"median":{"secs":0,"nanos":69120},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":66048},"max":{"secs":0,"nanos":70912}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":99763},"median":{"secs":0,"nanos":99840},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":99328},"max":{"secs":0,"nanos":100352}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[3,3],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":32,"out_channels":64,"shape":[16,16],"batch_size":32,"has_bias":true,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":184550},"median":{"secs":0,"nanos":184576},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":183296},"max":{"secs":0,"nanos":185600}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":1665484},"median":{"secs":0,"nanos":1968896},"variance":{"secs":0,"nanos":412},"min":{"secs":0,"nanos":702464},"max":{"secs":0,"nanos":2291712}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[3,3],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":64,"out_channels":128,"shape":[16,16],"batch_size":32,"has_bias":true,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":980838},"median":{"secs":0,"nanos":546560},"variance":{"secs":0,"nanos":446},"min":{"secs":0,"nanos":536576},"max":{"secs":0,"nanos":2251264}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":4615526},"median":{"secs":0,"nanos":5560320},"variance":{"secs":0,"nanos":1943},"min":{"secs":0,"nanos":2680576},"max":{"secs":0,"nanos":6129152}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[11,11],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":32,"out_channels":128,"shape":[16,16],"batch_size":64,"has_bias":false,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":3165670},"median":{"secs":0,"nanos":3128064},"variance":{"secs":0,"nanos":57},"min":{"secs":0,"nanos":2895616},"max":{"secs":0,"nanos":3765248}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":47714867},"median":{"secs":0,"nanos":47669504},"variance":{"secs":0,"nanos":189},"min":{"secs":0,"nanos":47037952},"max":{"secs":0,"nanos":48634368}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[11,11],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":32,"out_channels":64,"shape":[16,16],"batch_size":32,"has_bias":false,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":1553459},"median":{"secs":0,"nanos":2033152},"variance":{"secs":0,"nanos":547},"min":{"secs":0,"nanos":834816},"max":{"secs":0,"nanos":2732288}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":4090112},"median":{"secs":0,"nanos":4079616},"variance":{"secs":0,"nanos":34},"min":{"secs":0,"nanos":3832832},"max":{"secs":0,"nanos":4517888}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[11,11],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":32,"out_channels":32,"shape":[16,16],"batch_size":8,"has_bias":false,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":1318323},"median":{"secs":0,"nanos":740096},"variance":{"secs":0,"nanos":510},"min":{"secs":0,"nanos":737792},"max":{"secs":0,"nanos":2321664}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":1307059},"median":{"secs":0,"nanos":1739776},"variance":{"secs":0,"nanos":383},"min":{"secs":0,"nanos":708864},"max":{"secs":0,"nanos":2339328}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[3,3],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":8,"out_channels":32,"shape":[16,16],"batch_size":128,"has_bias":true,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":373760},"median":{"secs":0,"nanos":374272},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":370944},"max":{"secs":0,"nanos":375296}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":2783052},"median":{"secs":0,"nanos":2788864},"variance":{"secs":0,"nanos":1222},"min":{"secs":0,"nanos":1438464},"max":{"secs":0,"nanos":4578048}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[3,3],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":32,"out_channels":64,"shape":[16,16],"batch_size":128,"has_bias":true,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":705894},"median":{"secs":0,"nanos":706560},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":703232},"max":{"secs":0,"nanos":707840}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":7391232},"median":{"secs":0,"nanos":7377408},"variance":{"secs":0,"nanos":349},"min":{"secs":0,"nanos":6633472},"max":{"secs":0,"nanos":8690688}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[3,3],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":64,"out_channels":128,"shape":[16,16],"batch_size":128,"has_bias":true,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":1841510},"median":{"secs":0,"nanos":1739008},"variance":{"secs":0,"nanos":24},"min":{"secs":0,"nanos":1732608},"max":{"secs":0,"nanos":2240256}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":26589926},"median":{"secs":0,"nanos":12612096},"variance":{"secs":0,"nanos":811252},"min":{"secs":0,"nanos":12045568},"max":{"secs":0,"nanos":97125632}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[11,11],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":128,"out_channels":128,"shape":[16,16],"batch_size":64,"has_bias":false,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":7559526},"median":{"secs":0,"nanos":7646720},"variance":{"secs":0,"nanos":87},"min":{"secs":0,"nanos":7103744},"max":{"secs":0,"nanos":7992320}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":246500659},"median":{"secs":0,"nanos":247172096},"variance":{"secs":0,"nanos":2463},"min":{"secs":0,"nanos":244309760},"max":{"secs":0,"nanos":248831232}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[11,11],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":128,"out_channels":64,"shape":[16,16],"batch_size":32,"has_bias":false,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":3408281},"median":{"secs":0,"nanos":3393536},"variance":{"secs":0,"nanos":29},"min":{"secs":0,"nanos":3228672},"max":{"secs":0,"nanos":3644160}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":27782732},"median":{"secs":0,"nanos":27866880},"variance":{"secs":0,"nanos":90},"min":{"secs":0,"nanos":27389696},"max":{"secs":0,"nanos":28236800}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[11,11],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":128,"out_channels":32,"shape":[16,16],"batch_size":8,"has_bias":false,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":2949196},"median":{"secs":0,"nanos":2919424},"variance":{"secs":0,"nanos":54},"min":{"secs":0,"nanos":2779648},"max":{"secs":0,"nanos":3420928}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":2935091},"median":{"secs":0,"nanos":2931456},"variance":{"secs":0,"nanos":21},"min":{"secs":0,"nanos":2783744},"max":{"secs":0,"nanos":3187200}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[3,3],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":8,"out_channels":64,"shape":[16,16],"batch_size":64,"has_bias":true,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":377753},"median":{"secs":0,"nanos":378368},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":374528},"max":{"secs":0,"nanos":381184}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":3445504},"median":{"secs":0,"nanos":2308096},"variance":{"secs":0,"nanos":2527},"min":{"secs":0,"nanos":2204416},"max":{"secs":0,"nanos":6416384}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[3,3],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":128,"out_channels":256,"shape":[16,16],"batch_size":64,"has_bias":true,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":3816448},"median":{"secs":0,"nanos":3835136},"variance":{"secs":0,"nanos":135},"min":{"secs":0,"nanos":3115520},"max":{"secs":0,"nanos":4361472}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":25611827},"median":{"secs":0,"nanos":25628672},"variance":{"secs":0,"nanos":4680},"min":{"secs":0,"nanos":22836224},"max":{"secs":0,"nanos":30291968}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[11,11],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":64,"out_channels":256,"shape":[16,16],"batch_size":128,"has_bias":false,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":11354726},"median":{"secs":0,"nanos":11433728},"variance":{"secs":0,"nanos":101},"min":{"secs":0,"nanos":10961408},"max":{"secs":0,"nanos":11975936}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":462353817},"median":{"secs":0,"nanos":462727680},"variance":{"secs":0,"nanos":2134},"min":{"secs":0,"nanos":459892224},"max":{"secs":0,"nanos":464236544}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[11,11],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":64,"out_channels":64,"shape":[16,16],"batch_size":8,"has_bias":false,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":5502054},"median":{"secs":0,"nanos":5299968},"variance":{"secs":0,"nanos":687},"min":{"secs":0,"nanos":4439040},"max":{"secs":0,"nanos":6742528}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":6753382},"median":{"secs":0,"nanos":6347776},"variance":{"secs":0,"nanos":671},"min":{"secs":0,"nanos":5931520},"max":{"secs":0,"nanos":8413184}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[3,3],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":8,"out_channels":128,"shape":[16,16],"batch_size":64,"has_bias":true,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":789068},"median":{"secs":0,"nanos":736768},"variance":{"secs":0,"nanos":10},"min":{"secs":0,"nanos":735744},"max":{"secs":0,"nanos":998656}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":1668300},"median":{"secs":0,"nanos":1585920},"variance":{"secs":0,"nanos":39},"min":{"secs":0,"nanos":1492992},"max":{"secs":0,"nanos":2082048}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[3,3],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":256,"out_channels":512,"shape":[16,16],"batch_size":64,"has_bias":true,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":11402035},"median":{"secs":0,"nanos":11155200},"variance":{"secs":0,"nanos":410},"min":{"secs":0,"nanos":10774528},"max":{"secs":0,"nanos":12837120}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":600712908},"median":{"secs":0,"nanos":600226816},"variance":{"secs":0,"nanos":8699},"min":{"secs":0,"nanos":596258048},"max":{"secs":0,"nanos":606444032}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[11,11],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":64,"out_channels":512,"shape":[16,16],"batch_size":256,"has_bias":false,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":35776179},"median":{"secs":0,"nanos":35937024},"variance":{"secs":0,"nanos":650},"min":{"secs":0,"nanos":35028480},"max":{"secs":0,"nanos":37671936}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":2,"nanos":633985177},"median":{"secs":2,"nanos":633901824},"variance":{"secs":0,"nanos":21749},"min":{"secs":2,"nanos":627680000},"max":{"secs":2,"nanos":646173440}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[11,11],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":64,"out_channels":128,"shape":[16,16],"batch_size":8,"has_bias":false,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":1479296},"median":{"secs":0,"nanos":1441536},"variance":{"secs":0,"nanos":3},"min":{"secs":0,"nanos":1440256},"max":{"secs":0,"nanos":1567744}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":4182246},"median":{"secs":0,"nanos":4192768},"variance":{"secs":0,"nanos":39},"min":{"secs":0,"nanos":3794944},"max":{"secs":0,"nanos":4521728}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[3,3],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":8,"out_channels":128,"shape":[16,16],"batch_size":128,"has_bias":true,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":1631897},"median":{"secs":0,"nanos":1668096},"variance":{"secs":0,"nanos":26},"min":{"secs":0,"nanos":1463808},"max":{"secs":0,"nanos":1969152}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":3693977},"median":{"secs":0,"nanos":3342848},"variance":{"secs":0,"nanos":795},"min":{"secs":0,"nanos":2883584},"max":{"secs":0,"nanos":5521664}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[3,3],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":128,"out_channels":256,"shape":[16,16],"batch_size":128,"has_bias":true,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":8400819},"median":{"secs":0,"nanos":8390144},"variance":{"secs":0,"nanos":26},"min":{"secs":0,"nanos":8228864},"max":{"secs":0,"nanos":8792320}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":101213900},"median":{"secs":0,"nanos":100373504},"variance":{"secs":0,"nanos":5599},"min":{"secs":0,"nanos":99611648},"max":{"secs":0,"nanos":106675200}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[3,3],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":256,"out_channels":512,"shape":[16,16],"batch_size":128,"has_bias":true,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":21521024},"median":{"secs":0,"nanos":21521152},"variance":{"secs":0,"nanos":266},"min":{"secs":0,"nanos":20684544},"max":{"secs":0,"nanos":22410240}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":312103168},"median":{"secs":0,"nanos":312805888},"variance":{"secs":0,"nanos":4311},"min":{"secs":0,"nanos":307600128},"max":{"secs":0,"nanos":314340608}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[11,11],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":128,"out_channels":512,"shape":[16,16],"batch_size":256,"has_bias":false,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":70907212},"median":{"secs":0,"nanos":71002624},"variance":{"secs":0,"nanos":104},"min":{"secs":0,"nanos":70365696},"max":{"secs":0,"nanos":71508992}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":6,"nanos":370101939},"median":{"secs":6,"nanos":369424896},"variance":{"secs":0,"nanos":59845},"min":{"secs":6,"nanos":355879680},"max":{"secs":6,"nanos":383877120}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[11,11],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":128,"out_channels":256,"shape":[16,16],"batch_size":128,"has_bias":false,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":22101196},"median":{"secs":0,"nanos":21956608},"variance":{"secs":0,"nanos":107},"min":{"secs":0,"nanos":21836544},"max":{"secs":0,"nanos":22735360}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":1,"nanos":124295091},"median":{"secs":1,"nanos":123706624},"variance":{"secs":0,"nanos":5192},"min":{"secs":1,"nanos":121214720},"max":{"secs":1,"nanos":128329472}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[11,11],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":128,"out_channels":128,"shape":[16,16],"batch_size":8,"has_bias":false,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":2957440},"median":{"secs":0,"nanos":2889472},"variance":{"secs":0,"nanos":11},"min":{"secs":0,"nanos":2884864},"max":{"secs":0,"nanos":3177728}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":7329280},"median":{"secs":0,"nanos":7408128},"variance":{"secs":0,"nanos":30},"min":{"secs":0,"nanos":7056384},"max":{"secs":0,"nanos":7573504}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
