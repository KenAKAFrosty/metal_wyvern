{"key":{"key":{"Conv2d":{"kernel_size":[3,3],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":8,"out_channels":32,"shape":[16,16],"batch_size":64,"has_bias":true,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":117811},"median":{"secs":0,"nanos":118528},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":114432},"max":{"secs":0,"nanos":121344}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":180736},"median":{"secs":0,"nanos":180736},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":179968},"max":{"secs":0,"nanos":181504}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[3,3],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":32,"out_channels":64,"shape":[16,16],"batch_size":64,"has_bias":true,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":349926},"median":{"secs":0,"nanos":348928},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":344576},"max":{"secs":0,"nanos":361728}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":2936678},"median":{"secs":0,"nanos":2811904},"variance":{"secs":0,"nanos":243},"min":{"secs":0,"nanos":2619136},"max":{"secs":0,"nanos":4371200}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[3,3],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":64,"out_channels":128,"shape":[16,16],"batch_size":64,"has_bias":true,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":1922662},"median":{"secs":0,"nanos":2366208},"variance":{"secs":0,"nanos":407},"min":{"secs":0,"nanos":929024},"max":{"secs":0,"nanos":2436096}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":10795776},"median":{"secs":0,"nanos":10799872},"variance":{"secs":0,"nanos":23},"min":{"secs":0,"nanos":10569216},"max":{"secs":0,"nanos":11071744}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[11,11],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":64,"out_channels":128,"shape":[16,16],"batch_size":64,"has_bias":false,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":4919987},"median":{"secs":0,"nanos":4994560},"variance":{"secs":0,"nanos":48},"min":{"secs":0,"nanos":4657152},"max":{"secs":0,"nanos":5167360}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":112045619},"median":{"secs":0,"nanos":111992576},"variance":{"secs":0,"nanos":625},"min":{"secs":0,"nanos":110616576},"max":{"secs":0,"nanos":113622272}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[11,11],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":64,"out_channels":64,"shape":[16,16],"batch_size":32,"has_bias":false,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":3061683},"median":{"secs":0,"nanos":3093248},"variance":{"secs":0,"nanos":17},"min":{"secs":0,"nanos":2876416},"max":{"secs":0,"nanos":3300352}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":12766438},"median":{"secs":0,"nanos":12932096},"variance":{"secs":0,"nanos":54},"min":{"secs":0,"nanos":12404992},"max":{"secs":0,"nanos":13055232}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[11,11],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":64,"out_channels":32,"shape":[16,16],"batch_size":8,"has_bias":false,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":0,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":2779033},"median":{"secs":0,"nanos":2732544},"variance":{"secs":0,"nanos":26},"min":{"secs":0,"nanos":2638080},"max":{"secs":0,"nanos":3193856}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":2908518},"median":{"secs":0,"nanos":2961408},"variance":{"secs":0,"nanos":30},"min":{"secs":0,"nanos":2652416},"max":{"secs":0,"nanos":3170048}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[3,3],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":8,"out_channels":32,"shape":[16,16],"batch_size":32,"has_bias":true,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":68377},"median":{"secs":0,"nanos":69120},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":66048},"max":{"secs":0,"nanos":70912}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":99763},"median":{"secs":0,"nanos":99840},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":99328},"max":{"secs":0,"nanos":100352}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[3,3],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":32,"out_channels":64,"shape":[16,16],"batch_size":32,"has_bias":true,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":184550},"median":{"secs":0,"nanos":184576},"variance":{"secs":0,"nanos":0},"min":{"secs":0,"nanos":183296},"max":{"secs":0,"nanos":185600}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":1665484},"median":{"secs":0,"nanos":1968896},"variance":{"secs":0,"nanos":412},"min":{"secs":0,"nanos":702464},"max":{"secs":0,"nanos":2291712}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[3,3],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":64,"out_channels":128,"shape":[16,16],"batch_size":32,"has_bias":true,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":980838},"median":{"secs":0,"nanos":546560},"variance":{"secs":0,"nanos":446},"min":{"secs":0,"nanos":536576},"max":{"secs":0,"nanos":2251264}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":4615526},"median":{"secs":0,"nanos":5560320},"variance":{"secs":0,"nanos":1943},"min":{"secs":0,"nanos":2680576},"max":{"secs":0,"nanos":6129152}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[11,11],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":32,"out_channels":128,"shape":[16,16],"batch_size":64,"has_bias":false,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":3165670},"median":{"secs":0,"nanos":3128064},"variance":{"secs":0,"nanos":57},"min":{"secs":0,"nanos":2895616},"max":{"secs":0,"nanos":3765248}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":47714867},"median":{"secs":0,"nanos":47669504},"variance":{"secs":0,"nanos":189},"min":{"secs":0,"nanos":47037952},"max":{"secs":0,"nanos":48634368}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[11,11],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":32,"out_channels":64,"shape":[16,16],"batch_size":32,"has_bias":false,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":1553459},"median":{"secs":0,"nanos":2033152},"variance":{"secs":0,"nanos":547},"min":{"secs":0,"nanos":834816},"max":{"secs":0,"nanos":2732288}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":4090112},"median":{"secs":0,"nanos":4079616},"variance":{"secs":0,"nanos":34},"min":{"secs":0,"nanos":3832832},"max":{"secs":0,"nanos":4517888}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
{"key":{"key":{"Conv2d":{"kernel_size":[11,11],"stride":[1,1],"padding":[1,1],"dilation":[1,1],"groups":1,"in_channels":32,"out_channels":32,"shape":[16,16],"batch_size":8,"has_bias":false,"dtype":"F32"}},"checksum":"74b52c3158f5397428678da3fc8e493c"},"value":{"fastest_index":2,"results":[{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::im2col::conv_im2col<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":2,"computation":{"mean":{"secs":0,"nanos":1318323},"median":{"secs":0,"nanos":740096},"variance":{"secs":0,"nanos":510},"min":{"secs":0,"nanos":737792},"max":{"secs":0,"nanos":2321664}}}},{"Ok":{"name":"cubecl_runtime::tune::function_tunable::FunctionTunable<burn_cubecl::kernel::conv::direct::conv_direct<cubecl_wgpu::runtime::WgpuRuntime, f32, 2>, fn(burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, core::option::Option<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>>, burn_tensor::tensor::ops::modules::base::ConvOptions<2>) -> core::result::Result<burn_cubecl::tensor::base::CubeTensor<cubecl_wgpu::runtime::WgpuRuntime>, cubecl_convolution::components::error::ConvSetupError>>","index":0,"computation":{"mean":{"secs":0,"nanos":1307059},"median":{"secs":0,"nanos":1739776},"variance":{"secs":0,"nanos":383},"min":{"secs":0,"nanos":708864},"max":{"secs":0,"nanos":2339328}}}},{"Err":{"Unknown":"Unknown"}},{"Err":{"Unknown":"Unable to launch matmul because a required feature is unavailable: Cmma on lhs Scalar(Float(F16)) rhs Scalar(Float(F16)) and output Scalar(Float(F32)) with shape m=16, n=16, k=8 not supported.\n\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}},{"Err":{"Unknown":"Unable to launch matmul because could not find supported line size: NoValidLineSize\n"}}]}}
